{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b80cd9-2836-417f-b5e6-5c863a2ccd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushaldsouza/miniconda3/envs/dgl/lib/python3.12/site-packages/torchdata-0.8.0-py3.12-macosx-11.0-arm64.egg/torchdata/datapipes/__init__.py:18: UserWarning: \n",
      "################################################################################\n",
      "WARNING!\n",
      "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
      "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
      "to learn more and leave feedback.\n",
      "################################################################################\n",
      "\n",
      "  deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGL installed!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "os.environ['DGLBACKEND'] = \"pytorch\"\n",
    "\n",
    "# Install the CPU version.\n",
    "device = torch.device(\"cpu\")\n",
    "# !pip install --pre dgl -f https://data.dgl.ai/wheels-test/repo.html\n",
    "\n",
    "try:\n",
    "    import dgl\n",
    "    import dgl.graphbolt as gb\n",
    "    installed = True\n",
    "except ImportError as error:\n",
    "    installed = False\n",
    "    print(error)\n",
    "print(\"DGL installed!\" if installed else \"DGL not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4860f057-c368-4fa0-a166-58c25e87d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = gb.BuiltinDataset(\"ogbl-citation2\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8056147-330f-4534-a3bc-e53610bf5d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset.tasks[0].test_set)\n",
    "# print(dataset.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "937b833d-24fc-49be-951d-9afab4676391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(np.random.randint(0, 5, size=(5, 2)))\n",
    "# import numpy as np\n",
    "# personNodesWithLinks = [0, 1, 3, 4]\n",
    "# personNodesNp = np.array(personNodesWithLinks)\n",
    "# print(personNodesNp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c1d262f-28c8-4266-97aa-c857b9053838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[person:like:item] edges: [[0 1 2 1]\n",
      " [0 1 3 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the graph structure\n",
    "# Define directories\n",
    "base_dir = './sample_dataset'\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "personNodes = [0, 1, 2, 3, 4]\n",
    "personNodesWithLinks = [0, 1, 3, 4]\n",
    "personNodesNp = np.array(personNodesWithLinks)\n",
    "itemNodes = [0, 1, 2, 3]\n",
    "foodNodes = [0, 1, 2, 3]\n",
    "personItemEdges = [[0, 0], [1, 1], [2, 3], [1, 4]]\n",
    "personItemTotalEdges = [[[0, 0], [0,1]], [[1, 1], [1,2]], [[3, 2], [3, 1]], [[4, 1], [4,3]]]\n",
    "personItemEdgesNp = np.array(personItemEdges)\n",
    "personItemTotalEdgesNp = np.array(personItemTotalEdges)\n",
    "# df = pd.DataFrame(personItemEdgesNp)\n",
    "# df.to_csv(os.path.join(base_dir, \"person_item_edges.csv\"), index=False, header=False)\n",
    "print(f\"[item:liked_by:person] edges: {personItemEdgesNp.T}\\n\")\n",
    "np.save(os.path.join(base_dir, \"person_item_edges.npy\"), personItemEdgesNp)\n",
    "np.save(os.path.join(base_dir, \"person_item_edges_t.npy\"), personItemEdgesNp.T)\n",
    "np.save(os.path.join(base_dir, \"person_nodes.npy\"), personNodesNp)\n",
    "np.save(os.path.join(base_dir, \"person_item_edges_total.npy\"), personItemTotalEdgesNp)\n",
    "\n",
    "personFoodEdges = ([0, 0], [2, 1], [1, 2], [3, 4])\n",
    "personFoodEdgesNp = np.stack(personFoodEdges)\n",
    "# df = pd.DataFrame(personFoodEdgesNp)\n",
    "# df.to_csv(os.path.join(base_dir, \"person_food_edges.csv\"), index=False, header=False)\n",
    "np.save(os.path.join(base_dir, \"person_food_edges.npy\"), personFoodEdgesNp)\n",
    "np.save(os.path.join(base_dir, \"person_food_edges_t.npy\"), personFoodEdgesNp.T)\n",
    "\n",
    "# Add features to nodes (dummy features for this example)\n",
    "features = torch.eye(len(personNodes))  # Identity matrix as features\n",
    "\n",
    "# Save node features\n",
    "torch.save(features, os.path.join(base_dir, \"node_p_features.pt\"))\n",
    "torch.save(features * 2, os.path.join(base_dir, \"node_i_features.pt\"))\n",
    "torch.save(features * 3, os.path.join(base_dir, \"node_f_features.pt\"))\n",
    "\n",
    "# Create the metadata.yaml file\n",
    "yaml_content = f\"\"\"\n",
    "dataset_name: sample_graph\n",
    "graph:\n",
    "  nodes:\n",
    "    - type: person\n",
    "      num: {len(personNodes)}\n",
    "    - type: item\n",
    "      num: {len(itemNodes)}\n",
    "    - type: food\n",
    "      num: {len(foodNodes)}\n",
    "  edges:\n",
    "    - type: \"item:liked_by:person\"\n",
    "      format: numpy\n",
    "      path: ./person_item_edges_t.npy\n",
    "    - type: \"food:liked_by:person\"\n",
    "      format: numpy\n",
    "      path: ./person_food_edges_t.npy\n",
    "feature_data:\n",
    "  - domain: node\n",
    "    type: person\n",
    "    name: p_feat\n",
    "    format: torch\n",
    "    in_memory: false\n",
    "    path: node_p_features.pt\n",
    "  - domain: node\n",
    "    type: item\n",
    "    name: i_feat\n",
    "    format: torch\n",
    "    in_memory: false\n",
    "    path: node_i_features.pt\n",
    "  - domain: node\n",
    "    type: food\n",
    "    name: f_feat\n",
    "    format: torch\n",
    "    in_memory: false\n",
    "    path: node_f_features.pt\n",
    "tasks:\n",
    "  - name: link_prediction\n",
    "    train_set:\n",
    "      - type: \"item:liked_by:person\"\n",
    "        data:\n",
    "          - name: seeds\n",
    "            format: numpy\n",
    "            in_memory: false\n",
    "            path: ./person_item_edges.npy\n",
    "          # - name: seeds_with_negative\n",
    "          #   format: numpy\n",
    "          #   in_memory: false\n",
    "          #   path: ./person_item_edges_total.npy\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "# Save metadata.yaml\n",
    "with open(os.path.join(base_dir, \"metadata.yaml\"), \"w\") as f:\n",
    "    f.write(yaml_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a58846f-45d5-4b44-b8d1-d606b5b490b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./sample_dataset\n",
      "The on-disk dataset is re-preprocessing, so the existing preprocessed dataset has been removed.\n",
      "Start to preprocess the on-disk dataset.\n",
      "Finish preprocessing the on-disk dataset.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset to test\n",
    "base_dir = './sample_dataset'\n",
    "print(base_dir)\n",
    "dataset = gb.OnDiskDataset(base_dir, force_preprocess = True).load()\n",
    "# print(f\"Loaded graph: {graph}\")\n",
    "\n",
    "# features = dataset.feature\n",
    "# print(f\"Loaded feature store: {features}\")\n",
    "\n",
    "# tasks = dataset.tasks\n",
    "# lp_task = tasks[0]\n",
    "# print(f\"Loaded link prediction task: {lp_task}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3cbd541-6d89-4ca8-97fd-96c07a3598ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroItemSet(\n",
      "    itemsets={'item:liked_by:person': ItemSet(\n",
      "                 items=(tensor([[0, 0],\n",
      "                     [1, 1],\n",
      "                     [2, 3],\n",
      "                     [1, 4]], dtype=torch.int32),),\n",
      "                 names=('seeds',),\n",
      "             )},\n",
      "    names=('seeds',),\n",
      ")\n",
      "FusedCSCSamplingGraph(csc_indptr=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 5, 6, 8], dtype=torch.int32),\n",
      "                      indices=tensor([0, 4, 2, 5, 1, 6, 3, 5], dtype=torch.int32),\n",
      "                      total_num_nodes=13, num_edges={'food:liked_by:person': 4, 'item:liked_by:person': 4},\n",
      "                      node_type_offset=tensor([ 0,  4,  8, 13], dtype=torch.int32),\n",
      "                      type_per_edge=tensor([0, 1, 0, 1, 0, 1, 0, 1], dtype=torch.uint8),\n",
      "                      node_type_to_id={'food': 0, 'item': 1, 'person': 2},\n",
      "                      edge_type_to_id={'food:liked_by:person': 0, 'item:liked_by:person': 1},)\n",
      "TorchBasedFeatureStore(\n",
      "    {(<OnDiskFeatureDataDomain.NODE: 'node'>, 'person', 'p_feat'): TorchBasedFeature(\n",
      "        feature=tensor([[1., 0., 0., 0., 0.],\n",
      "                        [0., 1., 0., 0., 0.],\n",
      "                        [0., 0., 1., 0., 0.],\n",
      "                        [0., 0., 0., 1., 0.],\n",
      "                        [0., 0., 0., 0., 1.]]),\n",
      "        metadata={},\n",
      "    ), (<OnDiskFeatureDataDomain.NODE: 'node'>, 'item', 'i_feat'): TorchBasedFeature(\n",
      "        feature=tensor([[2., 0., 0., 0., 0.],\n",
      "                        [0., 2., 0., 0., 0.],\n",
      "                        [0., 0., 2., 0., 0.],\n",
      "                        [0., 0., 0., 2., 0.],\n",
      "                        [0., 0., 0., 0., 2.]]),\n",
      "        metadata={},\n",
      "    ), (<OnDiskFeatureDataDomain.NODE: 'node'>, 'food', 'f_feat'): TorchBasedFeature(\n",
      "        feature=tensor([[3., 0., 0., 0., 0.],\n",
      "                        [0., 3., 0., 0., 0.],\n",
      "                        [0., 0., 3., 0., 0.],\n",
      "                        [0., 0., 0., 3., 0.],\n",
      "                        [0., 0., 0., 0., 3.]]),\n",
      "        metadata={},\n",
      "    )}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "itemset = dataset.tasks[0].train_set\n",
    "graph = dataset.graph.to(device)\n",
    "feature = dataset.feature.to(device)\n",
    "print(itemset)\n",
    "print(graph)\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a203b79-ef22-4b89-94db-7f26768800ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def minibatcher(batch, names):\n",
    "#     print(batch)\n",
    "#     print(names)\n",
    "#     return gb.MiniBatch(seeds=batch.seeds)\n",
    "\n",
    "# sampler = gb.ItemSampler(\n",
    "#         itemset,\n",
    "#         batch_size=1,\n",
    "#         # minibatcher=minibatcher,\n",
    "#         shuffle=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c61c40d5-b40b-4691-b3a8-fa98e52cda46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(sampler))\n",
    "# for minibatch in sampler:\n",
    "#     print(minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6218f5a-4cbb-4c13-83af-6dff70987c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler = sampler.sample_uniform_negative(graph, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73cbf449-e88c-4cbe-8360-35316fa7845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for minibatch in sampler:\n",
    "#     # print(minibatch)\n",
    "    # print(minibatch.seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b3ede8-d0f5-4e3f-8275-eaa8386ff2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "# sampler = sampler.sample_neighbor(\n",
    "#         graph, [-1]\n",
    "#     )\n",
    "# sampler = sampler.transform(partial(gb.exclude_seed_edges, include_reverse_edges=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be323565-8a8d-4bf1-973d-62c1e4b19bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(sampler))\n",
    "# for minibatch in sampler:\n",
    "#     print(minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb48bfe8-79d6-4bc2-b88a-52545dbb5889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "# sampler = sampler.transform(\n",
    "#             partial(gb.exclude_seed_edges, include_reverse_edges=False)\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2be08f0-7546-4351-9869-49ab43c4beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for minibatch in sampler:\n",
    "#     print(minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "137de17b-3055-4d8c-a0f8-06fb2a9aceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapipe = gb.ItemSampler(itemset, batch_size=2, shuffle=True)\n",
    "datapipe = datapipe.copy_to(device)\n",
    "datapipe = datapipe.sample_neighbor(graph, [-1, -1, -1])\n",
    "datapipe = datapipe.fetch_feature(feature, node_feature_keys={\"person\": [\"p_feat\"], \"item\": [\"i_feat\"], \"food\": [\"f_feat\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3ba2f30-aaf0-4b34-8ab0-21bbf87e16d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_dataloader():\n",
    "    datapipe = gb.ItemSampler(itemset, batch_size=1, shuffle=True)\n",
    "    datapipe = datapipe.copy_to(device)\n",
    "    datapipe = datapipe.sample_neighbor(graph, [-1, -1, -1])\n",
    "    datapipe = datapipe.fetch_feature(feature, node_feature_keys={\"person\": [\"p_feat\"], \"item\": [\"i_feat\"], \"food\": [\"f_feat\"]})\n",
    "    return gb.DataLoader(datapipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a477c820-5ac6-4a95-ab69-5c0f23224184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "{'item:liked_by:person': tensor([[0, 0]], dtype=torch.int32)}\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([0], dtype=torch.int32), tensor([0], dtype=torch.int32))\n",
      "(tensor([0], dtype=torch.int32), tensor([0], dtype=torch.int32))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'item:liked_by:person': tensor([[2, 3]], dtype=torch.int32)}\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([0], dtype=torch.int32), tensor([0], dtype=torch.int32))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'item:liked_by:person': tensor([[1, 4]], dtype=torch.int32)}\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([0], dtype=torch.int32), tensor([0], dtype=torch.int32))\n",
      "(tensor([0], dtype=torch.int32), tensor([0], dtype=torch.int32))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'item:liked_by:person': tensor([[1, 1]], dtype=torch.int32)}\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([], dtype=torch.int32), tensor([], dtype=torch.int32))\n",
      "(tensor([0], dtype=torch.int32), tensor([0], dtype=torch.int32))\n",
      "(tensor([0], dtype=torch.int32), tensor([0], dtype=torch.int32))\n"
     ]
    }
   ],
   "source": [
    "for step, data in enumerate(create_train_dataloader()):\n",
    "    print(\"\\n\\n\\n\")\n",
    "    # print(data.seeds)\n",
    "    # print(data.blocks[0])\n",
    "    print(data.seeds)\n",
    "    print(data.blocks[0].edges(etype=('food', 'liked_by', 'person')))\n",
    "    print(data.blocks[0].edges(etype=('item', 'liked_by', 'person')))\n",
    "    print(data.blocks[1].edges(etype=('food', 'liked_by', 'person')))\n",
    "    print(data.blocks[1].edges(etype=('item', 'liked_by', 'person')))\n",
    "    print(data.blocks[2].edges(etype=('food', 'liked_by', 'person')))\n",
    "    print(data.blocks[2].edges(etype=('item', 'liked_by', 'person')))\n",
    "    # src, dest = data.blocks[1].edges(etype=('person', 'like', 'item'))\n",
    "    # print(src.numpy())\n",
    "    # print(dest.numpy())\n",
    "    # print(np.stack((src.numpy(), dest.numpy())))\n",
    "    # print(data.blocks[1])\n",
    "    # print(data.blocks[0].canonical_etypes)\n",
    "    # print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b60581-cd09-4cfe-b650-6a517caeba5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
