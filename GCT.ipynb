{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688306f4-58d3-4279-b9a2-e89fb33c94fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows from the first row group:\n",
      "   id                            buildingblock1_smiles buildingblock2_smiles  \\\n",
      "0   0  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21  C#CCOc1ccc(CN)cc1.Cl   \n",
      "1   1  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21  C#CCOc1ccc(CN)cc1.Cl   \n",
      "2   2  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21  C#CCOc1ccc(CN)cc1.Cl   \n",
      "3   3  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21  C#CCOc1ccc(CN)cc1.Cl   \n",
      "4   4  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21  C#CCOc1ccc(CN)cc1.Cl   \n",
      "\n",
      "     buildingblock3_smiles                                    molecule_smiles  \\\n",
      "0  Br.Br.NCC1CCCN1c1cccnn1  C#CCOc1ccc(CNc2nc(NCC3CCCN3c3cccnn3)nc(N[C@@H]...   \n",
      "1  Br.Br.NCC1CCCN1c1cccnn1  C#CCOc1ccc(CNc2nc(NCC3CCCN3c3cccnn3)nc(N[C@@H]...   \n",
      "2  Br.Br.NCC1CCCN1c1cccnn1  C#CCOc1ccc(CNc2nc(NCC3CCCN3c3cccnn3)nc(N[C@@H]...   \n",
      "3        Br.NCc1cccc(Br)n1  C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC...   \n",
      "4        Br.NCc1cccc(Br)n1  C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC...   \n",
      "\n",
      "  protein_name  binds  \n",
      "0         BRD4      0  \n",
      "1          HSA      0  \n",
      "2          sEH      0  \n",
      "3         BRD4      0  \n",
      "4          HSA      0  \n",
      "Total number of unique building blocks: 1145\n",
      "Total number of unique molecules: 98415610\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "\n",
    "# Read the file in chunks\n",
    "def process_chunk(chunk, unique_building_blocks, unique_molecules):\n",
    "    # Update the unique building blocks set\n",
    "    unique_building_blocks.update(chunk['buildingblock1_smiles'].unique())\n",
    "    unique_building_blocks.update(chunk['buildingblock2_smiles'].unique())\n",
    "    unique_building_blocks.update(chunk['buildingblock3_smiles'].unique())\n",
    "    \n",
    "    # Update the unique molecules set\n",
    "    unique_molecules.update(chunk['molecule_smiles'].unique())\n",
    "\n",
    "# Load the parquet file\n",
    "file_path = './train.parquet'\n",
    "batch_size = 100000\n",
    "parquet_file = pq.ParquetFile(file_path)\n",
    "\n",
    "# Initialize sets to keep track of unique building blocks and molecules\n",
    "unique_building_blocks = set()\n",
    "unique_molecules = set()\n",
    "\n",
    "# Iterate over the parquet file in batches\n",
    "num_row_groups = parquet_file.num_row_groups\n",
    "\n",
    "for i in range(num_row_groups):\n",
    "    # Read a batch of rows\n",
    "    row_group = parquet_file.read_row_group(i).to_pandas()\n",
    "\n",
    "    if i == 0:\n",
    "        print(\"First few rows from the first row group:\")\n",
    "        print(row_group.head())\n",
    "    \n",
    "    # Process the current chunk\n",
    "    process_chunk(row_group, unique_building_blocks, unique_molecules)\n",
    "\n",
    "# Output the total unique counts\n",
    "print(f\"Total number of unique building blocks: {len(unique_building_blocks)}\")\n",
    "print(f\"Total number of unique molecules: {len(unique_molecules)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb266164-524d-4660-83fe-b1c59594caa5",
   "metadata": {},
   "source": [
    "# Exhaustive List of Features for Small Molecules\n",
    "\n",
    "## Molecular Descriptors:\n",
    "- Molecular weight\n",
    "- Number of atoms\n",
    "- Number of bonds\n",
    "- Number of aromatic rings\n",
    "- Number of rotatable bonds\n",
    "- Topological polar surface area (TPSA)\n",
    "- LogP (octanol-water partition coefficient)\n",
    "\n",
    "## Atom-Level Features:\n",
    "- Atom types (e.g., C, H, O, N, S)\n",
    "- Hybridization states (sp, sp2, sp3)\n",
    "- Formal charge\n",
    "- Aromaticity\n",
    "- Degree (number of bonds to the atom)\n",
    "- Implicit and explicit hydrogen counts\n",
    "- Chirality\n",
    "\n",
    "## Bond-Level Features:\n",
    "- Bond types (single, double, triple, aromatic)\n",
    "- Conjugation\n",
    "- Ring membership\n",
    "- Stereo configuration (cis/trans)\n",
    "\n",
    "## Graph-Based Features:\n",
    "- Adjacency matrix\n",
    "- Distance matrix\n",
    "- Graph Laplacian\n",
    "\n",
    "## Physicochemical Properties:\n",
    "- Hydrogen bond donors and acceptors\n",
    "- Molecular refractivity\n",
    "- Molar volume\n",
    "- Electronegativity\n",
    "- Electron affinity\n",
    "\n",
    "## Structural Fingerprints:\n",
    "- MACCS keys\n",
    "- Morgan fingerprints\n",
    "- ECFP (Extended Connectivity Fingerprints)\n",
    "- RDKIT fingerprints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "767ee721-a593-45e9-888f-51156582d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors, AllChem, rdmolops\n",
    "from rdkit.DataStructs import ConvertToNumpyArray\n",
    "import numpy as np\n",
    "\n",
    "# Define encoding schemes outside the class\n",
    "ATOM_TYPES = ['C', 'H', 'O', 'N', 'S', 'F', 'Cl', 'Br', 'I', 'P', 'B']\n",
    "HYBRIDIZATION_STATES = ['SP', 'SP2', 'SP3', 'SP3D', 'SP3D2']\n",
    "CHIRAL_TAGS = ['CHI_UNSPECIFIED', 'CHI_TETRAHEDRAL_CW', 'CHI_TETRAHEDRAL_CCW', 'CHI_OTHER']\n",
    "BOND_TYPES = ['SINGLE', 'DOUBLE', 'TRIPLE', 'AROMATIC']\n",
    "STEREO_CONFIGURATIONS = ['STEREONONE', 'STEREOZ', 'STEREOE', 'STEREOCIS', 'STEREOTRANS']\n",
    "\n",
    "class SmallMoleculeFeatureExtractor:\n",
    "    def __init__(self, smiles):\n",
    "        self.smiles = smiles\n",
    "        self.mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    def get_molecular_descriptors(self):\n",
    "        descriptors = {\n",
    "            'molecular_weight': Descriptors.MolWt(self.mol),\n",
    "            'num_atoms': self.mol.GetNumAtoms(),\n",
    "            'num_bonds': self.mol.GetNumBonds(),\n",
    "            'num_aromatic_rings': rdMolDescriptors.CalcNumAromaticRings(self.mol),\n",
    "            'num_rotatable_bonds': Descriptors.NumRotatableBonds(self.mol),\n",
    "            'tpsa': Descriptors.TPSA(self.mol),\n",
    "            'logp': Descriptors.MolLogP(self.mol)\n",
    "        }\n",
    "        return descriptors\n",
    "\n",
    "    def one_hot_encode(self, value, categories):\n",
    "        encoding = [0] * len(categories)\n",
    "        if value in categories:\n",
    "            encoding[categories.index(value)] = 1\n",
    "        return encoding\n",
    "\n",
    "    def get_atom_level_features(self):\n",
    "        atom_features = []\n",
    "        for atom in self.mol.GetAtoms():\n",
    "            atom_features.append([\n",
    "                self.one_hot_encode(atom.GetSymbol(), ATOM_TYPES),\n",
    "                self.one_hot_encode(str(atom.GetHybridization()), HYBRIDIZATION_STATES),\n",
    "                atom.GetFormalCharge(),\n",
    "                atom.GetIsAromatic(),\n",
    "                atom.GetDegree(),\n",
    "                atom.GetImplicitValence(),\n",
    "                atom.GetTotalNumHs(),\n",
    "                self.one_hot_encode(str(atom.GetChiralTag()), CHIRAL_TAGS)\n",
    "            ])\n",
    "        return atom_features\n",
    "\n",
    "    def get_bond_level_features(self):\n",
    "        bond_features = []\n",
    "        for bond in self.mol.GetBonds():\n",
    "            bond_features.append([\n",
    "                self.one_hot_encode(str(bond.GetBondType()), BOND_TYPES),\n",
    "                bond.GetIsConjugated(),\n",
    "                bond.IsInRing(),\n",
    "                self.one_hot_encode(str(bond.GetStereo()), STEREO_CONFIGURATIONS)\n",
    "            ])\n",
    "        return bond_features\n",
    "\n",
    "    def get_graph_based_features(self):\n",
    "        adj_matrix = rdmolops.GetAdjacencyMatrix(self.mol)\n",
    "        dist_matrix = rdmolops.GetDistanceMatrix(self.mol)\n",
    "        return {\n",
    "            'adjacency_matrix': adj_matrix,\n",
    "            'distance_matrix': dist_matrix,\n",
    "        }\n",
    "\n",
    "    def get_physicochemical_properties(self):\n",
    "        properties = {\n",
    "            'h_bond_donors': Descriptors.NumHDonors(self.mol),\n",
    "            'h_bond_acceptors': Descriptors.NumHAcceptors(self.mol),\n",
    "            'molecular_refractivity': Descriptors.MolMR(self.mol),\n",
    "            'molar_volume': Descriptors.MolLogP(self.mol) / Descriptors.MolWt(self.mol)\n",
    "        }\n",
    "        return properties\n",
    "\n",
    "    def get_structural_fingerprints(self):\n",
    "        maccs_keys = AllChem.GetMACCSKeysFingerprint(self.mol)\n",
    "        morgan_fp = AllChem.GetMorganFingerprintAsBitVect(self.mol, 2)\n",
    "        rdk_fp = Chem.RDKFingerprint(self.mol)\n",
    "\n",
    "        maccs_keys_np = np.zeros((1,))\n",
    "        ConvertToNumpyArray(maccs_keys, maccs_keys_np)\n",
    "\n",
    "        morgan_fp_np = np.zeros((1,))\n",
    "        ConvertToNumpyArray(morgan_fp, morgan_fp_np)\n",
    "\n",
    "        rdk_fp_np = np.zeros((1,))\n",
    "        ConvertToNumpyArray(rdk_fp, rdk_fp_np)\n",
    "        \n",
    "        return {\n",
    "            'maccs_keys': maccs_keys_np,\n",
    "            'morgan_fp': morgan_fp_np,\n",
    "            'rdkit_fp': rdk_fp_np\n",
    "        }\n",
    "\n",
    "    def extract_features(self):\n",
    "        features = {\n",
    "            'molecular_descriptors': self.get_molecular_descriptors(),\n",
    "            'atom_level_features': self.get_atom_level_features(),\n",
    "            'bond_level_features': self.get_bond_level_features(),\n",
    "            'graph_based_features': self.get_graph_based_features(),\n",
    "            'physicochemical_properties': self.get_physicochemical_properties(),\n",
    "            'structural_fingerprints': self.get_structural_fingerprints()\n",
    "        }\n",
    "        return features\n",
    "\n",
    "    def flatten_features(self):\n",
    "        # Extract individual features\n",
    "        molecular_descriptors = self.get_molecular_descriptors()\n",
    "        physicochemical_properties = self.get_physicochemical_properties()\n",
    "        structural_fingerprints = self.get_structural_fingerprints()\n",
    "        graph_based_features = self.get_graph_based_features()\n",
    "    \n",
    "        # Flatten the structural fingerprints\n",
    "        flattened_structural_fingerprints = np.concatenate([\n",
    "            structural_fingerprints['maccs_keys'],\n",
    "            structural_fingerprints['morgan_fp'],\n",
    "            structural_fingerprints['rdkit_fp']\n",
    "        ])\n",
    "    \n",
    "        # Convert molecular descriptors and physicochemical properties to arrays\n",
    "        molecular_descriptors_array = np.array(list(molecular_descriptors.values()))\n",
    "        physicochemical_properties_array = np.array(list(physicochemical_properties.values()))\n",
    "\n",
    "        # Extract adjacency and distance matrices\n",
    "        adjacency_matrix = graph_based_features['adjacency_matrix']\n",
    "        distance_matrix = graph_based_features['distance_matrix']\n",
    "    \n",
    "        return {\n",
    "            'molecular_descriptors': molecular_descriptors_array,\n",
    "            'physicochemical_properties': physicochemical_properties_array,\n",
    "            'structural_fingerprints': flattened_structural_fingerprints,\n",
    "            'adjacency_matrix': adjacency_matrix,\n",
    "            'distance_matrix': distance_matrix\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a1be6c-f0a2-4f50-803b-3d3ab03a60bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "molecular_descriptors: [349.386   26.      28.       2.       6.      75.63     3.3917]\n",
      "physicochemical_properties: [2.00000000e+00 3.00000000e+00 9.76955000e+01 9.70760133e-03]\n",
      "structural_fingerprints: [0. 0. 0. ... 1. 1. 1.]\n",
      "adjacency_matrix: [[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0]]\n",
      "distance_matrix: [[ 0.  1.  2.  3.  4.  5.  6.  6.  4.  5.  6.  6.  7.  8.  9. 10. 11. 12.\n",
      "  11. 10. 10. 11. 12. 11. 10.  9.]\n",
      " [ 1.  0.  1.  2.  3.  4.  5.  5.  3.  4.  5.  5.  6.  7.  8.  9. 10. 11.\n",
      "  10.  9.  9. 10. 11. 10.  9.  8.]\n",
      " [ 2.  1.  0.  1.  2.  3.  4.  4.  2.  3.  4.  4.  5.  6.  7.  8.  9. 10.\n",
      "   9.  8.  8.  9. 10.  9.  8.  7.]\n",
      " [ 3.  2.  1.  0.  1.  2.  3.  3.  1.  2.  3.  3.  4.  5.  6.  7.  8.  9.\n",
      "   8.  7.  7.  8.  9.  8.  7.  6.]\n",
      " [ 4.  3.  2.  1.  0.  1.  2.  2.  2.  3.  4.  4.  5.  6.  7.  8.  9. 10.\n",
      "   9.  8.  8.  9. 10.  9.  8.  7.]\n",
      " [ 5.  4.  3.  2.  1.  0.  1.  1.  3.  4.  5.  5.  6.  7.  8.  9. 10. 11.\n",
      "  10.  9.  9. 10. 11. 10.  9.  8.]\n",
      " [ 6.  5.  4.  3.  2.  1.  0.  2.  4.  5.  6.  6.  7.  8.  9. 10. 11. 12.\n",
      "  11. 10. 10. 11. 12. 11. 10.  9.]\n",
      " [ 6.  5.  4.  3.  2.  1.  2.  0.  4.  5.  6.  6.  7.  8.  9. 10. 11. 12.\n",
      "  11. 10. 10. 11. 12. 11. 10.  9.]\n",
      " [ 4.  3.  2.  1.  2.  3.  4.  4.  0.  1.  2.  2.  3.  4.  5.  6.  7.  8.\n",
      "   7.  6.  6.  7.  8.  7.  6.  5.]\n",
      " [ 5.  4.  3.  2.  3.  4.  5.  5.  1.  0.  1.  1.  2.  3.  4.  5.  6.  7.\n",
      "   6.  5.  5.  6.  7.  6.  5.  4.]\n",
      " [ 6.  5.  4.  3.  4.  5.  6.  6.  2.  1.  0.  2.  3.  4.  5.  6.  7.  8.\n",
      "   7.  6.  6.  7.  8.  7.  6.  5.]\n",
      " [ 6.  5.  4.  3.  4.  5.  6.  6.  2.  1.  2.  0.  1.  2.  3.  4.  5.  6.\n",
      "   5.  4.  4.  5.  6.  5.  4.  3.]\n",
      " [ 7.  6.  5.  4.  5.  6.  7.  7.  3.  2.  3.  1.  0.  1.  2.  3.  4.  5.\n",
      "   4.  3.  3.  4.  5.  4.  3.  2.]\n",
      " [ 8.  7.  6.  5.  6.  7.  8.  8.  4.  3.  4.  2.  1.  0.  1.  2.  3.  4.\n",
      "   3.  2.  2.  3.  4.  3.  2.  1.]\n",
      " [ 9.  8.  7.  6.  7.  8.  9.  9.  5.  4.  5.  3.  2.  1.  0.  1.  2.  3.\n",
      "   2.  1.  2.  3.  4.  4.  3.  2.]\n",
      " [10.  9.  8.  7.  8.  9. 10. 10.  6.  5.  6.  4.  3.  2.  1.  0.  1.  2.\n",
      "   3.  2.  3.  4.  5.  5.  4.  3.]\n",
      " [11. 10.  9.  8.  9. 10. 11. 11.  7.  6.  7.  5.  4.  3.  2.  1.  0.  1.\n",
      "   2.  3.  4.  5.  6.  6.  5.  4.]\n",
      " [12. 11. 10.  9. 10. 11. 12. 12.  8.  7.  8.  6.  5.  4.  3.  2.  1.  0.\n",
      "   1.  2.  3.  4.  5.  6.  5.  4.]\n",
      " [11. 10.  9.  8.  9. 10. 11. 11.  7.  6.  7.  5.  4.  3.  2.  3.  2.  1.\n",
      "   0.  1.  2.  3.  4.  5.  4.  3.]\n",
      " [10.  9.  8.  7.  8.  9. 10. 10.  6.  5.  6.  4.  3.  2.  1.  2.  3.  2.\n",
      "   1.  0.  1.  2.  3.  4.  3.  2.]\n",
      " [10.  9.  8.  7.  8.  9. 10. 10.  6.  5.  6.  4.  3.  2.  2.  3.  4.  3.\n",
      "   2.  1.  0.  1.  2.  3.  2.  1.]\n",
      " [11. 10.  9.  8.  9. 10. 11. 11.  7.  6.  7.  5.  4.  3.  3.  4.  5.  4.\n",
      "   3.  2.  1.  0.  1.  2.  3.  2.]\n",
      " [12. 11. 10.  9. 10. 11. 12. 12.  8.  7.  8.  6.  5.  4.  4.  5.  6.  5.\n",
      "   4.  3.  2.  1.  0.  1.  2.  3.]\n",
      " [11. 10.  9.  8.  9. 10. 11. 11.  7.  6.  7.  5.  4.  3.  4.  5.  6.  6.\n",
      "   5.  4.  3.  2.  1.  0.  1.  2.]\n",
      " [10.  9.  8.  7.  8.  9. 10. 10.  6.  5.  6.  4.  3.  2.  3.  4.  5.  5.\n",
      "   4.  3.  2.  3.  2.  1.  0.  1.]\n",
      " [ 9.  8.  7.  6.  7.  8.  9.  9.  5.  4.  5.  3.  2.  1.  2.  3.  4.  4.\n",
      "   3.  2.  1.  2.  3.  2.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "smiles = \"C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21\"\n",
    "extractor = SmallMoleculeFeatureExtractor(smiles)\n",
    "features = extractor.flatten_features()\n",
    "for feature, value in features.items():\n",
    "    print(f\"{feature}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fca0bf-cb35-4f82-bbd5-0f24f2bf50aa",
   "metadata": {},
   "source": [
    "# Feature Extraction from Protein Structure PDB File\n",
    "\n",
    "## Structural Features\n",
    "\n",
    "### Amino Acid Composition:\n",
    "- Frequency of each amino acid type in the binding site.\n",
    "- Frequency of amino acid types in the entire protein.\n",
    "\n",
    "### Secondary Structure:\n",
    "- Percentage of alpha-helices, beta-sheets, and random coils in the binding site.\n",
    "- Secondary structure elements around the binding site.\n",
    "\n",
    "### Tertiary Structure:\n",
    "- 3D coordinates of the binding site.\n",
    "- Distance between key residues in the binding site.\n",
    "\n",
    "### Binding Site Characteristics:\n",
    "- Volume and surface area of the binding site.\n",
    "- Shape descriptors (e.g., sphericity, elongation).\n",
    "\n",
    "## Physicochemical Properties\n",
    "\n",
    "### Hydrophobicity:\n",
    "- Hydrophobic and hydrophilic residue distribution in the binding site.\n",
    "- Hydrophobic surface area.\n",
    "\n",
    "### Charge Distribution:\n",
    "- Number and type of charged residues (positive and negative).\n",
    "- Electrostatic potential distribution.\n",
    "\n",
    "### Polarity:\n",
    "- Number of polar residues.\n",
    "- Polar surface area.\n",
    "\n",
    "### Solvent Accessibility:\n",
    "- Solvent-accessible surface area (SASA) of residues in the binding site.\n",
    "\n",
    "### Hydrogen Bonding:\n",
    "- Number of potential hydrogen bond donors and acceptors.\n",
    "- Hydrogen bond network in the binding site.\n",
    "\n",
    "### Van der Waals Interactions:\n",
    "- Van der Waals interaction potential of the binding site.\n",
    "\n",
    "## Geometric Features\n",
    "\n",
    "### Distance Metrics:\n",
    "- Pairwise distances between all residues in the binding site.\n",
    "- Distance to the nearest surface residue.\n",
    "\n",
    "### Angles and Dihedrals:\n",
    "- Angles and dihedral angles between residues in the binding site.\n",
    "\n",
    "## Chemical Environment\n",
    "\n",
    "### Residue Environment:\n",
    "- Local chemical environment of each residue (e.g., neighboring residues within a certain radius).\n",
    "\n",
    "### Ligand Interaction Sites:\n",
    "- Specific interaction sites for known ligands (if available).\n",
    "\n",
    "## Dynamic Properties\n",
    "\n",
    "### Flexibility:\n",
    "- B-factors or temperature factors indicating residue flexibility.\n",
    "\n",
    "### Molecular Dynamics Simulations:\n",
    "- Root mean square fluctuation (RMSF) of residues in the binding site.\n",
    "- Conformational changes over time.\n",
    "\n",
    "## Topological Features\n",
    "\n",
    "### Graph-based Features:\n",
    "- Protein structure represented as a graph with nodes (residues) and edges (interactions).\n",
    "- Degree centrality, betweenness centrality, and clustering coefficient of residues in the binding site.\n",
    "\n",
    "## Energy-based Features\n",
    "\n",
    "### Binding Energy:\n",
    "- Estimated binding free energy of known ligands.\n",
    "- Energy components (van der Waals, electrostatic, solvation) from docking simulations.\n",
    "\n",
    "## Protein-Ligand Interaction Features\n",
    "\n",
    "### Docking Scores:\n",
    "- Scores from molecular docking simulations with various ligands.\n",
    "\n",
    "### Interaction Profiles:\n",
    "- Interaction fingerprints summarizing the types and strengths of interactions with ligands.\n",
    "\n",
    "## Evolutionary Features\n",
    "\n",
    "### Conservation:\n",
    "- Sequence conservation of residues in the binding site (e.g., from multiple sequence alignment).\n",
    "\n",
    "### Mutational Impact:\n",
    "- Predicted impact of mutations on binding site residues.\n",
    "\n",
    "## Experimental Data\n",
    "\n",
    "### Experimental Binding Data:\n",
    "- Known binding affinities (e.g., Kd, Ki, IC50) for small molecules.\n",
    "\n",
    "## Contextual Features\n",
    "\n",
    "### Functional Annotations:\n",
    "- Biological function and pathway involvement of the protein.\n",
    "- Known protein-protein interactions.\n",
    "\n",
    "## Integration and Representation\n",
    "\n",
    "### Feature Scaling and Normalization:\n",
    "- Standardize and normalize features for input into the deep learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49e9f49b-65e5-40ff-9103-a170239f38ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBParser, is_aa, NeighborSearch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "class ProteinFeatureExtractor:\n",
    "    def __init__(self, pdb_file):\n",
    "        self.pdb_file = pdb_file\n",
    "        self.structure = self.load_structure()\n",
    "        self.ligand_resnames = self.detect_ligands()\n",
    "        self.graph = self.construct_graph()\n",
    "\n",
    "    def load_structure(self):\n",
    "        # Load the PDB structure\n",
    "        parser = PDBParser()\n",
    "        structure = parser.get_structure('protein', self.pdb_file)\n",
    "        return structure\n",
    "\n",
    "    def detect_ligands(self):\n",
    "        # Detect ligand residue names by excluding standard amino acids and water\n",
    "        ligands = set()\n",
    "        standard_amino_acids = {'ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLN', 'GLU', 'GLY', 'HIS', 'ILE', \n",
    "                                'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL'}\n",
    "        water_residues = {'HOH'}\n",
    "        for residue in self.structure.get_residues():\n",
    "            resname = residue.resname\n",
    "            if resname not in standard_amino_acids and resname not in water_residues:\n",
    "                ligands.add(resname)\n",
    "        return list(ligands)\n",
    "\n",
    "    def get_amino_acid_composition(self):\n",
    "        # Get the composition of amino acids in the protein\n",
    "        amino_acids = [residue.resname for residue in self.structure.get_residues() if residue.id[0] == ' ']\n",
    "        aa_counts = {aa: amino_acids.count(aa) for aa in set(amino_acids)}\n",
    "        return aa_counts\n",
    "\n",
    "\n",
    "    def get_flexibility(self):\n",
    "        # Calculate the flexibility of the protein based on B-factors\n",
    "        flexibility = []\n",
    "        for atom in self.structure.get_atoms():\n",
    "            flexibility.append(atom.bfactor)\n",
    "        return np.mean(flexibility)\n",
    "\n",
    "    def get_distance_metrics(self):\n",
    "        # Calculate distance metrics between residues in the protein\n",
    "        distances = []\n",
    "        for chain in self.structure.get_chains():\n",
    "            print(f\"Processing chain: {chain.id}\")\n",
    "            residues = [res for res in chain if 'CA' in res.child_dict]  # Filter residues with 'CA' atom\n",
    "            for i, res1 in enumerate(residues):\n",
    "                ca1 = res1.child_dict.get('CA')\n",
    "                if ca1 is None:\n",
    "                    print(f\"Residue {res1} does not have a CA atom.\")\n",
    "                    continue\n",
    "                for j, res2 in enumerate(residues):\n",
    "                    if i < j:\n",
    "                        ca2 = res2.child_dict.get('CA')\n",
    "                        if ca2 is None:\n",
    "                            print(f\"Residue {res2} does not have a CA atom.\")\n",
    "                            continue\n",
    "                        try:\n",
    "                            distance = ca1 - ca2\n",
    "                            distances.append(distance)\n",
    "                        except KeyError as e:\n",
    "                            print(f\"Error calculating distance: {e}\")\n",
    "        return distances\n",
    "\n",
    "    def construct_graph(self, cutoff=4.0):\n",
    "        # Initialize an undirected graph\n",
    "        G = nx.Graph()\n",
    "\n",
    "        # Add nodes for each residue\n",
    "        for chain in self.structure.get_chains():\n",
    "            for residue in chain:\n",
    "                if is_aa(residue):\n",
    "                    G.add_node(residue.id, residue=residue)\n",
    "\n",
    "        # Add edges based on distance cutoff\n",
    "        atoms = list(self.structure.get_atoms())\n",
    "        ns = NeighborSearch(atoms)\n",
    "        for atom in atoms:\n",
    "            if atom.element == 'H':  # Skip hydrogen atoms\n",
    "                continue\n",
    "            neighbors = ns.search(atom.coord, cutoff)\n",
    "            for neighbor in neighbors:\n",
    "                if neighbor.element == 'H':  # Skip hydrogen atoms\n",
    "                    continue\n",
    "                res1 = atom.get_parent()\n",
    "                res2 = neighbor.get_parent()\n",
    "                if res1 != res2:\n",
    "                    G.add_edge(res1.id, res2.id, weight=atom - neighbor)\n",
    "\n",
    "        return G\n",
    "\n",
    "    def extract_graph_features(self):\n",
    "        # Adjacency matrix\n",
    "        adjacency_matrix = nx.adjacency_matrix(self.graph).todense()\n",
    "\n",
    "        # Distance matrix (Floyd-Warshall algorithm)\n",
    "        distance_matrix = nx.floyd_warshall_numpy(self.graph)\n",
    "\n",
    "        # Degree centrality\n",
    "        degree_centrality = nx.degree_centrality(self.graph)\n",
    "\n",
    "        # Betweenness centrality\n",
    "        betweenness_centrality = nx.betweenness_centrality(self.graph)\n",
    "\n",
    "        # Clustering coefficient\n",
    "        clustering_coefficient = nx.clustering(self.graph)\n",
    "\n",
    "        # Ensure features are in a consistent order\n",
    "        nodes = list(self.graph.nodes)\n",
    "        degree_centrality = np.array([degree_centrality[node] for node in nodes])\n",
    "        betweenness_centrality = np.array([betweenness_centrality[node] for node in nodes])\n",
    "        clustering_coefficient = np.array([clustering_coefficient[node] for node in nodes])\n",
    "\n",
    "        # Aggregate features into a dictionary\n",
    "        features = {\n",
    "            'adjacency_matrix': adjacency_matrix,\n",
    "            'distance_matrix': distance_matrix,\n",
    "            'degree_centrality': degree_centrality,\n",
    "            'betweenness_centrality': betweenness_centrality,\n",
    "            'clustering_coefficient': clustering_coefficient\n",
    "        }\n",
    "\n",
    "        return features\n",
    "\n",
    "    def extract_features(self):\n",
    "        # Extract various features from the protein structure\n",
    "        amino_acid_composition = self.get_amino_acid_composition()\n",
    "        flexibility = self.get_flexibility()\n",
    "        distance_metrics = self.get_distance_metrics()\n",
    "        graph_features = self.extract_graph_features()\n",
    "\n",
    "        features = {\n",
    "            \"amino_acid_composition\": amino_acid_composition,\n",
    "            \"flexibility\": flexibility,\n",
    "            \"distance_metrics\": distance_metrics,\n",
    "            \"graph_features\": graph_features\n",
    "        }\n",
    "        return features\n",
    "\n",
    "    def extract_and_aggregate_features(self):\n",
    "        # Extract various features from the protein structure\n",
    "        amino_acid_composition = self.get_amino_acid_composition()\n",
    "        flexibility = self.get_flexibility()\n",
    "        distance_metrics = self.get_distance_metrics()\n",
    "        graph_features = self.extract_graph_features()\n",
    "    \n",
    "        # Combine amino acid composition and flexibility into a single array\n",
    "        amino_acid_comp_values = list(amino_acid_composition.values())\n",
    "        combined_features = amino_acid_comp_values + [flexibility]\n",
    "    \n",
    "        features = {\n",
    "            \"protein_combined_features\": np.array(combined_features),\n",
    "            \"distance_metrics\": distance_metrics,\n",
    "            \"degree_centrality\": graph_features[\"degree_centrality\"],\n",
    "            \"betweenness_centrality\": graph_features[\"betweenness_centrality\"],\n",
    "            \"clustering_coefficient\": graph_features[\"clustering_coefficient\"],\n",
    "        }\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ea1a6-9e37-4247-b1b2-11ad9b98ca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_file = \"./ALB.pdb\"\n",
    "extractor = ProteinFeatureExtractor(pdb_file)\n",
    "aggregated_features = extractor.extract_and_aggregate_features()\n",
    "print(aggregated_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "462d97ec-01b3-4e75-acca-a4bb2a369d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushaldsouza/miniconda3/envs/dgl/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpq\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Import your feature extractors here\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# from your_feature_extractor_module import SmallMoleculeFeatureExtractor, ProteinFeatureExtractor\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_chunk\u001b[39m(chunk, G, node_features, unique_building_blocks, unique_molecules, protein_features, protein_dict):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import your feature extractors here\n",
    "# from your_feature_extractor_module import SmallMoleculeFeatureExtractor, ProteinFeatureExtractor\n",
    "\n",
    "def process_chunk(chunk, G, node_features, unique_building_blocks, unique_molecules, protein_features, protein_dict):\n",
    "    for index, row in chunk.iterrows():\n",
    "        # Building block features extraction\n",
    "        bb1_extractor = SmallMoleculeFeatureExtractor(row['buildingblock1_smiles'])\n",
    "        bb1_features = bb1_extractor.flatten_features()\n",
    "        \n",
    "        bb2_extractor = SmallMoleculeFeatureExtractor(row['buildingblock2_smiles'])\n",
    "        bb2_features = bb2_extractor.flatten_features()\n",
    "\n",
    "        bb3_extractor = SmallMoleculeFeatureExtractor(row['buildingblock3_smiles'])\n",
    "        bb3_features = bb3_extractor.flatten_features()\n",
    "\n",
    "        # Molecule features extraction\n",
    "        mol_extractor = SmallMoleculeFeatureExtractor(row['molecule_smiles'])\n",
    "        mol_features = mol_extractor.flatten_features()\n",
    "\n",
    "        # Add nodes and features\n",
    "        for bb, features in zip([row['buildingblock1_smiles'], row['buildingblock2_smiles'], row['buildingblock3_smiles']], [bb1_features, bb2_features, bb3_features]):\n",
    "            if bb not in unique_building_blocks:\n",
    "                node_id = len(unique_building_blocks)\n",
    "                unique_building_blocks[bb] = node_id\n",
    "                G.add_nodes(1, ntype='building_block')\n",
    "                node_features['building_block'][node_id] = torch.tensor(features['structural_fingerprints'])\n",
    "                \n",
    "                # Add molecular descriptors, physicochemical properties, adjacency matrix, distance matrix nodes\n",
    "                G.add_nodes(1, ntype='molecular_descriptor')\n",
    "                node_features['molecular_descriptor'][node_id] = torch.tensor(features['molecular_descriptors'])\n",
    "                G.add_edge(node_id, node_id + len(unique_building_blocks), etype='has')\n",
    "                \n",
    "                G.add_nodes(1, ntype='physicochemical_properties')\n",
    "                node_features['physicochemical_properties'][node_id] = torch.tensor(features['physicochemical_properties'])\n",
    "                G.add_edge(node_id, node_id + 2 * len(unique_building_blocks), etype='has')\n",
    "                \n",
    "                G.add_nodes(1, ntype='adjacency_matrix')\n",
    "                node_features['adjacency_matrix'][node_id] = torch.tensor(features['adjacency_matrix'])\n",
    "                G.add_edge(node_id, node_id + 3 * len(unique_building_blocks), etype='has')\n",
    "                \n",
    "                G.add_nodes(1, ntype='distance_matrix')\n",
    "                node_features['distance_matrix'][node_id] = torch.tensor(features['distance_matrix'])\n",
    "                G.add_edge(node_id, node_id + 4 * len(unique_building_blocks), etype='has')\n",
    "\n",
    "        if row['molecule_smiles'] not in unique_molecules:\n",
    "            node_id = len(unique_molecules)\n",
    "            unique_molecules[row['molecule_smiles']] = node_id\n",
    "            G.add_nodes(1, ntype='molecule')\n",
    "            node_features['molecule'][node_id] = torch.tensor(mol_features['structural_fingerprints'])\n",
    "\n",
    "            # Add molecular descriptors, physicochemical properties, adjacency matrix, distance matrix nodes\n",
    "            G.add_nodes(1, ntype='molecular_descriptor')\n",
    "            node_features['molecular_descriptor'][node_id] = torch.tensor(mol_features['molecular_descriptors'])\n",
    "            G.add_edge(node_id, node_id + len(unique_molecules), etype='has')\n",
    "            \n",
    "            G.add_nodes(1, ntype='physicochemical_properties')\n",
    "            node_features['physicochemical_properties'][node_id] = torch.tensor(mol_features['physicochemical_properties'])\n",
    "            G.add_edge(node_id, node_id + 2 * len(unique_molecules), etype='has')\n",
    "            \n",
    "            G.add_nodes(1, ntype='adjacency_matrix')\n",
    "            node_features['adjacency_matrix'][node_id] = torch.tensor(mol_features['adjacency_matrix'])\n",
    "            G.add_edge(node_id, node_id + 3 * len(unique_molecules), etype='has')\n",
    "            \n",
    "            G.add_nodes(1, ntype='distance_matrix')\n",
    "            node_features['distance_matrix'][node_id] = torch.tensor(mol_features['distance_matrix'])\n",
    "            G.add_edge(node_id, node_id + 4 * len(unique_molecules), etype='has')\n",
    "\n",
    "        # Create contains edges\n",
    "        G.add_edge(unique_molecules[row['molecule_smiles']], unique_building_blocks[row['buildingblock1_smiles']], etype='contains')\n",
    "        G.add_edge(unique_molecules[row['molecule_smiles']], unique_building_blocks[row['buildingblock2_smiles']], etype='contains')\n",
    "        G.add_edge(unique_molecules[row['molecule_smiles']], unique_building_blocks[row['buildingblock3_smiles']], etype='contains')\n",
    "\n",
    "        # Protein features\n",
    "        protein_name = row['protein_name']\n",
    "        if protein_name not in protein_features:\n",
    "            pdb_file = f\"./{protein_name}.pdb\"\n",
    "            protein_extractor = ProteinFeatureExtractor(pdb_file)\n",
    "            protein_features[protein_name] = protein_extractor.extract_and_aggregate_features()\n",
    "            protein_dict[protein_name] = len(protein_dict)\n",
    "\n",
    "        # Add protein node and its features\n",
    "        protein_id = protein_dict[protein_name]\n",
    "        if protein_name not in protein_features:\n",
    "            G.add_nodes(1, ntype='protein')\n",
    "            node_features['protein'][protein_id] = torch.tensor(protein_features[protein_name]['protein_combined_features'])\n",
    "\n",
    "            # Add protein's distance metrics, degree centrality, betweenness centrality, clustering coefficient\n",
    "            G.add_nodes(1, ntype='distance_metrics')\n",
    "            node_features['distance_metrics'][protein_id] = torch.tensor(protein_features[protein_name]['distance_metrics'])\n",
    "            G.add_edge(protein_id, protein_id + len(protein_dict), etype='has')\n",
    "\n",
    "            G.add_nodes(1, ntype='degree_centrality')\n",
    "            node_features['degree_centrality'][protein_id] = torch.tensor(protein_features[protein_name]['degree_centrality'])\n",
    "            G.add_edge(protein_id, protein_id + 2 * len(protein_dict), etype='has')\n",
    "\n",
    "            G.add_nodes(1, ntype='betweenness_centrality')\n",
    "            node_features['betweenness_centrality'][protein_id] = torch.tensor(protein_features[protein_name]['betweenness_centrality'])\n",
    "            G.add_edge(protein_id, protein_id + 3 * len(protein_dict), etype='has')\n",
    "\n",
    "            G.add_nodes(1, ntype='clustering_coefficient')\n",
    "            node_features['clustering_coefficient'][protein_id] = torch.tensor(protein_features[protein_name]['clustering_coefficient'])\n",
    "            G.add_edge(protein_id, protein_id + 4 * len(protein_dict), etype='has')\n",
    "\n",
    "        # Create binds edge\n",
    "        G.add_edge(unique_molecules[row['molecule_smiles']], protein_id, etype='binds')\n",
    "\n",
    "\n",
    "def create_and_save_graph(file_path, chunk_size=100000):\n",
    "    # Initialize graph and features\n",
    "    G = dgl.heterograph({})\n",
    "\n",
    "    node_features = {\n",
    "        'building_block': {},\n",
    "        'molecule': {},\n",
    "        'molecular_descriptor': {},\n",
    "        'physicochemical_properties': {},\n",
    "        'adjacency_matrix': {},\n",
    "        'distance_matrix': {},\n",
    "        'protein': {},\n",
    "        'distance_metrics': {},\n",
    "        'degree_centrality': {},\n",
    "        'betweenness_centrality': {},\n",
    "        'clustering_coefficient': {}\n",
    "    }\n",
    "\n",
    "    unique_building_blocks = {}\n",
    "    unique_molecules = {}\n",
    "    protein_features = {}\n",
    "    protein_dict = {}\n",
    "\n",
    "    # Load the parquet file in chunks\n",
    "    parquet_file = pq.ParquetFile(file_path)\n",
    "    num_row_groups = parquet_file.num_row_groups\n",
    "\n",
    "    # Perform stratified sampling to ensure good coverage of the three proteins\n",
    "    all_data = []\n",
    "    for i in range(num_row_groups):\n",
    "        chunk = parquet_file.read_row_group(i).to_pandas()\n",
    "        all_data.append(chunk)\n",
    "    all_data = pd.concat(all_data)\n",
    "\n",
    "    # Combine protein_name and binds columns to ensure stratification on both\n",
    "    all_data['stratify_col'] = all_data['protein_name'].astype(str) + '_' + all_data['binds'].astype(str)\n",
    "    \n",
    "    # Perform stratified sampling\n",
    "    stratified_sample, _ = train_test_split(all_data, test_size=0.98, stratify=all_data['stratify_col'])\n",
    "\n",
    "    for i in range(0, len(stratified_sample), chunk_size):\n",
    "        chunk = stratified_sample.iloc[i:i + chunk_size]\n",
    "        process_chunk(chunk, G, node_features, unique_building_blocks, unique_molecules, protein_features, protein_dict)\n",
    "\n",
    "    # Convert lists to tensors and ensure each node feature is named \"feature\"\n",
    "    for ntype in G.ntypes:\n",
    "        features = [node_features[ntype][i] for i in range(len(node_features[ntype]))]\n",
    "        G.nodes[ntype].data['feature'] = torch.stack(features)\n",
    "\n",
    "    # Save the graph and node features\n",
    "    dgl.save_graphs('heterograph.dgl', [G], node_data=G.nodes())\n",
    "\n",
    "    bb_df = pd.DataFrame(unique_building_blocks.items(), columns=['smiles', 'id'])\n",
    "    bb_df.to_parquet('building_blocks.parquet', index=False)\n",
    "    \n",
    "    protein_df = pd.DataFrame(protein_dict.items(), columns=['name', 'id'])\n",
    "    protein_df.to_parquet('proteins.parquet', index=False)\n",
    "\n",
    "\n",
    "def load_graph_and_features(graph_path, bb_path, protein_path):\n",
    "    # Load the graph and node features\n",
    "    graphs, node_data = dgl.load_graphs(graph_path)\n",
    "    G = graphs[0]\n",
    "\n",
    "    bb_df = pd.read_parquet(bb_path)\n",
    "    protein_df = pd.read_parquet(protein_path)\n",
    "\n",
    "    return G, bb_df, protein_df\n",
    "\n",
    "\n",
    "# Create and save the graph\n",
    "create_and_save_graph('./train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab4a981-c249-4ccc-8bc0-64ffaf43bb73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
